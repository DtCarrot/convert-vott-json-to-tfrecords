{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow==1.13.1 in /home/darren/anaconda3/lib/python3.6/site-packages\n",
      "Requirement already satisfied: numpy>=1.13.3 in /home/darren/anaconda3/lib/python3.6/site-packages (from tensorflow==1.13.1)\n",
      "Requirement already satisfied: six>=1.10.0 in /home/darren/anaconda3/lib/python3.6/site-packages (from tensorflow==1.13.1)\n",
      "Requirement already satisfied: astor>=0.6.0 in /home/darren/anaconda3/lib/python3.6/site-packages (from tensorflow==1.13.1)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /home/darren/anaconda3/lib/python3.6/site-packages (from tensorflow==1.13.1)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /home/darren/anaconda3/lib/python3.6/site-packages (from tensorflow==1.13.1)\n",
      "Requirement already satisfied: wheel>=0.26 in /home/darren/anaconda3/lib/python3.6/site-packages (from tensorflow==1.13.1)\n",
      "Requirement already satisfied: absl-py>=0.1.6 in /home/darren/anaconda3/lib/python3.6/site-packages (from tensorflow==1.13.1)\n",
      "Requirement already satisfied: tensorflow-estimator<1.14.0rc0,>=1.13.0 in /home/darren/anaconda3/lib/python3.6/site-packages (from tensorflow==1.13.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/darren/anaconda3/lib/python3.6/site-packages (from tensorflow==1.13.1)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /home/darren/anaconda3/lib/python3.6/site-packages (from tensorflow==1.13.1)\n",
      "Requirement already satisfied: gast>=0.2.0 in /home/darren/anaconda3/lib/python3.6/site-packages (from tensorflow==1.13.1)\n",
      "Requirement already satisfied: tensorboard<1.14.0,>=1.13.0 in /home/darren/anaconda3/lib/python3.6/site-packages (from tensorflow==1.13.1)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /home/darren/anaconda3/lib/python3.6/site-packages (from tensorflow==1.13.1)\n",
      "Requirement already satisfied: setuptools in /home/darren/anaconda3/lib/python3.6/site-packages (from protobuf>=3.6.1->tensorflow==1.13.1)\n",
      "Requirement already satisfied: mock>=2.0.0 in /home/darren/anaconda3/lib/python3.6/site-packages (from tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow==1.13.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/darren/anaconda3/lib/python3.6/site-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/darren/anaconda3/lib/python3.6/site-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1)\n",
      "Requirement already satisfied: h5py in /home/darren/anaconda3/lib/python3.6/site-packages (from keras-applications>=1.0.6->tensorflow==1.13.1)\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 19.1.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow==1.13.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import json\n",
    "from zipfile import ZipFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_bb_box(food_image_url):\n",
    "    with open(food_image_url) as f:\n",
    "        bb_json = json.load(f)\n",
    "        return bb_json\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Copyright 2017 The TensorFlow Authors. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ==============================================================================\n",
    "\n",
    "\"\"\"Utility functions for creating TFRecord data sets.\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "def int64_feature(value):\n",
    "  return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "\n",
    "def int64_list_feature(value):\n",
    "  return tf.train.Feature(int64_list=tf.train.Int64List(value=value))\n",
    "\n",
    "\n",
    "def bytes_feature(value):\n",
    "  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "\n",
    "def bytes_list_feature(value):\n",
    "  return tf.train.Feature(bytes_list=tf.train.BytesList(value=value))\n",
    "\n",
    "\n",
    "def float_list_feature(value):\n",
    "  return tf.train.Feature(float_list=tf.train.FloatList(value=value))\n",
    "\n",
    "\n",
    "def read_examples_list(path):\n",
    "  \"\"\"Read list of training or validation examples.\n",
    "  The file is assumed to contain a single example per line where the first\n",
    "  token in the line is an identifier that allows us to find the image and\n",
    "  annotation xml for that example.\n",
    "  For example, the line:\n",
    "  xyz 3\n",
    "  would allow us to find files xyz.jpg and xyz.xml (the 3 would be ignored).\n",
    "  Args:\n",
    "    path: absolute path to examples list file.\n",
    "  Returns:\n",
    "    list of example identifiers (strings).\n",
    "  \"\"\"\n",
    "  with tf.gfile.GFile(path) as fid:\n",
    "    lines = fid.readlines()\n",
    "  return [line.strip().split(' ')[0] for line in lines]\n",
    "\n",
    "\n",
    "def recursive_parse_xml_to_dict(xml):\n",
    "  \"\"\"Recursively parses XML contents to python dict.\n",
    "  We assume that `object` tags are the only ones that can appear\n",
    "  multiple times at the same level of a tree.\n",
    "  Args:\n",
    "    xml: xml tree obtained by parsing XML file contents using lxml.etree\n",
    "  Returns:\n",
    "    Python dictionary holding XML contents.\n",
    "  \"\"\"\n",
    "  if not xml:\n",
    "    return {xml.tag: xml.text}\n",
    "  result = {}\n",
    "  for child in xml:\n",
    "    child_result = recursive_parse_xml_to_dict(child)\n",
    "    if child.tag != 'object':\n",
    "      result[child.tag] = child_result[child.tag]\n",
    "    else:\n",
    "      if child.tag not in result:\n",
    "        result[child.tag] = []\n",
    "      result[child.tag].append(child_result[child.tag])\n",
    "  return {xml.tag: result}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_tf_example(data_info):\n",
    "  # TODO START: Populate the following variables from your example.\n",
    "  height = data_info['height'] # Image height\n",
    "  width = data_info['width'] # Image width\n",
    "  filename = data_info['filename'].encode() # Filename of the image. Empty if image is not from file\n",
    "  encoded_image_data = data_info['encoded_image_data'] # Encoded image bytes\n",
    "  image_format = data_info['image_format'].encode() # b'jpeg' or b'png'\n",
    "\n",
    "  xmins = data_info['xmins'] # List of normalized left x coordinates in bounding box (1 per box)\n",
    "  xmaxs = data_info['xmaxs'] # List of normalized right x coordinates in bounding box\n",
    "             # (1 per box)\n",
    "  ymins = data_info['ymins'] # List of normalized top y coordinates in bounding box (1 per box)\n",
    "  ymaxs = data_info['ymaxs'] # List of normalized bottom y coordinates in bounding box\n",
    "             # (1 per box)\n",
    "  classes_text = data_info['classes_text'] # List of string class name of bounding box (1 per box)\n",
    "  classes = data_info['classes'] # List of integer class id of bounding box (1 per box)\n",
    "  # TODO END\n",
    "  tf_label_and_data = tf.train.Example(features=tf.train.Features(feature={\n",
    "      'image/height': int64_feature(height),\n",
    "      'image/width': int64_feature(width),\n",
    "      'image/filename': bytes_feature(filename),\n",
    "      'image/source_id': bytes_feature(filename),\n",
    "      'image/encoded': bytes_feature(encoded_image_data),\n",
    "      'image/format': bytes_feature(image_format),\n",
    "      'image/object/bbox/xmin': float_list_feature(xmins),\n",
    "      'image/object/bbox/xmax': float_list_feature(xmaxs),\n",
    "      'image/object/bbox/ymin': float_list_feature(ymins),\n",
    "      'image/object/bbox/ymax': float_list_feature(ymaxs),\n",
    "      'image/object/class/text': bytes_list_feature(classes_text),\n",
    "      'image/object/class/label': int64_list_feature(classes),\n",
    "  }))\n",
    "  return tf_label_and_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_json_to_tf(json_path, output_path):\n",
    "    food_bb_json = process_bb_box(json_path)\n",
    "    assets = food_bb_json['assets']\n",
    "    tags = list(map(lambda x: x['name'], food_bb_json['tags']))\n",
    "    writer = tf.python_io.TFRecordWriter(output_path)\n",
    "    for key in assets:\n",
    "        image_metadata = assets[key]\n",
    "        width = image_metadata['asset']['size']['width']\n",
    "        height = image_metadata['asset']['size']['height']\n",
    "        filename = image_metadata['asset']['path']\n",
    "        image_format = image_metadata['asset']['format']\n",
    "        xmins = []\n",
    "        xmaxs = []\n",
    "        ymins = []\n",
    "        ymaxs = []\n",
    "        classes_text = []\n",
    "        classes = []\n",
    "        regions = image_metadata['regions']\n",
    "\n",
    "        data_info = {\n",
    "            'filename': filename,\n",
    "            'image_format': image_format, \n",
    "            'width': width,\n",
    "            'height': height\n",
    "        }\n",
    "        with tf.gfile.GFile(food_image_url + '/' + filename, 'rb') as fid:\n",
    "            encoded_image_data = fid.read()\n",
    "            data_info['encoded_image_data'] = encoded_image_data\n",
    "\n",
    "        for bbox_region in regions:\n",
    "            xmin = bbox_region['points'][0]['x'] / width\n",
    "            ymin = bbox_region['points'][0]['y'] / height\n",
    "            xmax = bbox_region['points'][2]['x'] / width\n",
    "            ymax = bbox_region['points'][2]['y'] / height\n",
    "            class_text = bbox_region['tags'][0]\n",
    "            class_id = tags.index(class_text) + 1\n",
    "            class_text = class_text.encode()\n",
    "            xmins.append(xmin)\n",
    "            ymins.append(ymin)\n",
    "            xmaxs.append(xmax)\n",
    "            ymaxs.append(ymax)\n",
    "            classes_text.append(class_text)\n",
    "            classes.append(class_id)\n",
    "        data_info['xmins'] = xmins\n",
    "        data_info['ymins'] = ymins\n",
    "        data_info['xmaxs'] = xmaxs\n",
    "        data_info['ymaxs'] = ymaxs\n",
    "        data_info['classes_text'] = classes_text\n",
    "        data_info['classes'] = classes\n",
    "        tf_example = create_tf_example(data_info)\n",
    "        writer.write(tf_example.SerializeToString())\n",
    "    writer.close()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_train_path = './vott-json-export/Food-Detection-App-export.json'\n",
    "json_eval_path = './vott-json-export/Food-Detection-App-(Eval)-export.json'\n",
    "tfrecord_train_path = './bbox-train.record'\n",
    "tfrecord_eval_path = './bbox-eval.record'\n",
    "process_json_to_tf(json_train_path, tfrecord_train_path)\n",
    "process_json_to_tf(json_eval_path, tfrecord_eval_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
